{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project: French Grand Debat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Introduction :\n",
    "\n",
    "First, we would like to choose a problematic according to the data we collected. The aim of this project could be to answer the following questions:\n",
    "\n",
    "* What are the 5 most important ideas on each theme?\n",
    "* Can we build different profiles of people with their ideas on the 4 themes?\n",
    "* Can we predict themes about which people could be interested in if those people answered questions only about 3 on 4 themes? \n",
    " \n",
    "#### Doability :\n",
    "\n",
    "We are going to import the data, then check if the ids of people who submitted ideas on different themes are the same. If not, we won't be able to answer the second question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies imported\n",
    "import src.utils as ut #read data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fiscalite = ut.read_data('data/LA_FISCALITE_ET_LES_DEPENSES_PUBLIQUES.json')\n",
    "df_democratie = ut.read_data('data/DEMOCRATIE_ET_CITOYENNETE.json')\n",
    "df_ecologie = ut.read_data('data/LA_TRANSITION_ECOLOGIQUE.json')\n",
    "df_organisation = ut.read_data('data/ORGANISATION_DE_LETAT_ET_DES_SERVICES_PUBLICS.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author ID : VXNlcjoxMjViYWQ4Yi0xZmM0LTExZTktOTRkMi1mYTE2M2VlYjExZTE=\n",
      "* In fiscalite survey, author has zip code : 93320\n",
      "* In democratie survey, author has not answered...\n",
      "* In ecologie survey, author has not answered...\n",
      "* In organisation survey, author has not answered...\n",
      "\n",
      "############################\n",
      "\n",
      "Author ID : VXNlcjplYWEyMzA2MC0xZGEzLTExZTktOTRkMi1mYTE2M2VlYjExZTE=\n",
      "* In fiscalite survey, author has zip code : 82290\n",
      "* In democratie survey, author has zip code : 82290\n",
      "* In ecologie survey, author has not answered...\n",
      "* In organisation survey, author has zip code : 82290\n",
      "\n",
      "############################\n",
      "\n",
      "Author ID : VXNlcjo5ZjllMTFiZS0xYTQ3LTExZTktOTRkMi1mYTE2M2VlYjExZTE=\n",
      "* In fiscalite survey, author has zip code : 59700\n",
      "* In democratie survey, author has not answered...\n",
      "* In ecologie survey, author has not answered...\n",
      "* In organisation survey, author has not answered...\n",
      "\n",
      "############################\n",
      "\n",
      "Author ID : VXNlcjplZjFhMGViMS0xZTU4LTExZTktOTRkMi1mYTE2M2VlYjExZTE=\n",
      "* In fiscalite survey, author has zip code : 13008\n",
      "* In democratie survey, author has zip code : 13008\n",
      "* In ecologie survey, author has zip code : 13008\n",
      "* In organisation survey, author has zip code : 13008\n",
      "\n",
      "############################\n",
      "\n",
      "Author ID : VXNlcjo5MTU4MjZmMS0yMTg1LTExZTktOTRkMi1mYTE2M2VlYjExZTE=\n",
      "* In fiscalite survey, author has zip code : 27670\n",
      "* In democratie survey, author has not answered...\n",
      "* In ecologie survey, author has not answered...\n",
      "* In organisation survey, author has zip code : 27670\n",
      "\n",
      "############################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "for i in np.random.randint(len(df_fiscalite), size=5):\n",
    "    auth = df_fiscalite.loc[i, 'authorId']\n",
    "    print(\"Author ID : \" + auth)\n",
    "\n",
    "    dfs = np.array([[\"fiscalite\", df_fiscalite], [\"democratie\", df_democratie], [\"ecologie\", df_ecologie], [\"organisation\", df_organisation]])\n",
    "    for df in dfs:\n",
    "        code = df[1].loc[df[1]['authorId'] == auth, 'authorZipCode']\n",
    "        if(len(code) > 0):\n",
    "            code = code.values[0]\n",
    "            print(\"* In \" + df[0] + \" survey, author has zip code : \" + str(code))\n",
    "        else:\n",
    "            print(\"* In \" + df[0] + \" survey, author has not answered...\")\n",
    "    print(\"\\n############################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the previous lines, we can see that the `authorId` is likely to be an unique id whaterver the dataframe (zip code is the same).**\n",
    "\n",
    "### How many people answered several themes ?\n",
    "\n",
    "In order to build type-profiles, we need a large number of people who answered questions on several themes. That is what we will try to find with the following code.\n",
    "\n",
    "**Be careful, this cell takes a lot of time to run !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b0ca590499c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_auth_id_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_auth_id_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'authorId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mauth_answers_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauth_answers_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# allAuthIds is the sets of all the authorIds\n",
    "allAuthIds = []\n",
    "for i in range(4):\n",
    "    allAuthIds.extend(set(dfs[i,1]['authorId'].values))\n",
    "allAuthIds = set(allAuthIds)\n",
    "\n",
    "# all_auth_id_array is the sorted array of all the authorIds\n",
    "all_auth_id_array = np.sort(np.array(list(allAuthIds)))\n",
    "\n",
    "# auth_answers_count[i,j] is 1 if all_auth_id_array[i] has answered survey dfs[j]\n",
    "auth_answers_count = np.zeros((len(allAuthIds), 4), dtype=int)\n",
    "for j in range(4):\n",
    "    for i in range(len(all_auth_id_array)):\n",
    "        auth = all_auth_id_array[i]\n",
    "        line = dfs[j,1].loc[dfs[j,1]['authorId'] == auth]\n",
    "        if(len(line) > 0):\n",
    "            auth_answers_count[i,j] = auth_answers_count[i,j] + 1\n",
    "\n",
    "            \n",
    "# This cell aims to save the auth_answers_count array in auth_answers_count.csv\n",
    "np.savetxt(\"auth_answers_count.csv\", auth_answers_count, fmt='%1u', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can run this cell instead to load auth_answers_count from csv :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read auth_answers_count from auth_answers_count.csv\n",
    "auth_answers_count = np.loadtxt('auth_answers_count.csv', dtype=int ,delimiter=\",\")\n",
    "\n",
    "print(\"auth_answers_count :\")\n",
    "print(auth_answers_count)\n",
    "\n",
    "# number_of_survey_taken[i] is the number of survey answered by all_auth_id_array[i]\n",
    "number_of_survey_taken = np.sum(auth_answers_count, axis=1)\n",
    "# number_of_participants_by_survey[i] is the number of participants to survey dfs[j]\n",
    "number_of_participants_by_survey = np.sum(auth_answers_count, axis=0)\n",
    "\n",
    "print(\"#######################\")\n",
    "print(\"number of participant by survey :\")\n",
    "for i in range(4):\n",
    "    print(dfs[i,0] + \" : \" + str(number_of_participants_by_survey[i]))\n",
    "\n",
    "# number_of_participant_to_several_surveys[i] is the number of participants that have\n",
    "# answerd to i surveys out of the 4 (0<i<5)\n",
    "number_of_participant_to_several_surveys = np.bincount(number_of_survey_taken)\n",
    "\n",
    "print(\"#######################\")\n",
    "print(\"number of participant to x surveys :\")\n",
    "for i in range(5):\n",
    "    print(str(number_of_participant_to_several_surveys[i]) + \" people have participed to \"\n",
    "          + str(i) + \" different surveys.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume\n",
    "\n",
    "Total number of participants by survey:\n",
    "\n",
    "* **fiscalite :** 54609\n",
    "* **democratie :** 32800\n",
    "* **ecologie :** 42963\n",
    "* **organisation :** 35328\n",
    "\n",
    "Number of participant to $x$ surveys :\n",
    "\n",
    "* 54970 people have participated to only one survey\n",
    "* 17552 people have participated to 2 surveys\n",
    "* 10038 people have participated to 3 survey\n",
    "* 11378 people have participated to 4 survey\n",
    "\n",
    "These preliminaries let us think that what we wanted to do for this project is doable, because the number of people who answered on several themes is pretty large. We are now looking for a method to build these type-profiles.\n",
    "\n",
    "\n",
    "# General ideas about this project\n",
    "\n",
    "After having processed the data, our project will be articulated in two parts: \n",
    "\n",
    "* **Learning :** We are going to build a model able to find different groups (or trends opinion) based on clustering. We will train our model on people who answered the 4 themes. We will make some tests to determine a number of different profiles (maximum of 10 clusters) that seems relevant. Then we will check the relevance of these type profiles.\n",
    "* **Check :** We will test our model applying it to the test dataset (people who have participated to 3 surveys) to check if it is able to correctly predict the themes.\n",
    "\n",
    "Based on the result of the last point we will be able to say whether or not our goal is reached, and if the dataset given is enough to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
